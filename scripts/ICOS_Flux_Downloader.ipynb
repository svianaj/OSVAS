{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1b3153d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16334/3369797552.py:7: UserWarning: \n",
      "It is highly recommended to replace the following import:\n",
      "\"from icoscp.cpb.dobj import Dobj\"\n",
      "  with\n",
      "\"from icoscp.dobj import Dobj\"\n",
      "Find out more here: https://icos-carbon-portal.github.io/pylib/icoscp/install/#upgrade-guide\n",
      "  from icoscp.cpb.dobj import Dobj\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "import time\n",
    "import datetime\n",
    "from icoscp.cpb.dobj import Dobj\n",
    "import os\n",
    "from icoscp_core.icos import bootstrap\n",
    "from icoscp import cpauth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "264b05de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Input parameters (edit these)\n",
    "OSVAS='/home/pn56/OSVASgh/'\n",
    "station_name = \"Majadas_south\"\n",
    "start_date = \"2016-06-01\"\n",
    "end_date = \"2016-07-31\"\n",
    "station_list_path = os.path.join(OSVAS,\"./sqlites/station_list_SURFEX.csv\")\n",
    "dataset_doi = \"https://meta.icos-cp.eu/objects/dDlpnhS3XKyZjB22MUzP_nAm\"\n",
    "\n",
    "#In the following dictionary, select the variable names from dataset_doi \n",
    "#and how they will be renamed in the output sqlite\n",
    "\n",
    "variables = {'H_F_MDS': 'H', 'LE_F_MDS': 'LE'}\n",
    "\n",
    "#Authenticate into ICOS:\n",
    "cookie_file_path = os.path.join(OSVAS,\"./sqlites/icos_cookie.txt\")\n",
    "cookie_token=open(cookie_file_path,'r').readline().rstrip()\n",
    "meta, data = bootstrap.fromCookieToken(cookie_token)\n",
    "cpauth.init_by(data.auth)\n",
    "\n",
    "#Test: If the authentication went well, these lines of code will not fail:\n",
    "import icoscp\n",
    "from icoscp.dobj import Dobj\n",
    "obj_flux='https://meta.icos-cp.eu/objects/dDlpnhS3XKyZjB22MUzP_nAm'\n",
    "dobj_flux=Dobj(obj_flux).data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9de0029c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Define helper functions\n",
    "def load_station_metadata(path):\n",
    "    return pd.read_csv(path)\n",
    "\n",
    "def get_station_info(name, metadata_df):\n",
    "    row = metadata_df[metadata_df['name'] == name]\n",
    "    if row.empty:\n",
    "        raise ValueError(f\"Station '{name}' not found in the metadata file.\")\n",
    "    return row.iloc[0]\n",
    "\n",
    "def fetch_flux_data(doi, cookie_token):\n",
    "    # Bootstrap session using your token\n",
    "    meta, data = bootstrap.fromCookieToken(cookie_token)\n",
    "    cpauth.init_by(data.auth)\n",
    "\n",
    "    # Fetch the data object\n",
    "    dobj = Dobj(doi)\n",
    "    df = dobj.data\n",
    "    return df\n",
    "\n",
    "\n",
    "def fetch_flux_data(doi):\n",
    "    dobj = Dobj(doi)\n",
    "    df = dobj.data\n",
    "    return df\n",
    "\n",
    "\n",
    "def process_data(df, station_info, start, end):\n",
    "    df['valid_dttm'] = pd.to_datetime(df['TIMESTAMP'], utc=True)\n",
    "    df = df[(df['valid_dttm'] >= start) & (df['valid_dttm'] <= end)]\n",
    "    df['valid_dttm'] = df['TIMESTAMP'].view('int64')\n",
    "    df = df.dropna(subset=['H_F_MDS', 'LE_F_MDS'])\n",
    "    df['SID'] = station_info['SID']\n",
    "    df['lat'] = station_info['lat']\n",
    "    df['lon'] = station_info['lon']\n",
    "    df['elev'] = station_info['elev']\n",
    "    return df[['valid_dttm', 'SID', 'lat', 'lon', 'elev', 'H_F_MDS', 'LE_F_MDS']]\n",
    "\n",
    "def process_data(df, station_info, start, end, variable_names):\n",
    "    \"\"\"\n",
    "    Processes a DataFrame, selecting data within a time range, adding station information,\n",
    "    and renaming specified columns based on a dictionary.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame with a 'TIMESTAMP' column and the variables to process.\n",
    "        station_info (dict): A dictionary containing station information with keys 'SID', 'lat', 'lon', and 'elev'.\n",
    "        start (str or datetime): The start timestamp for filtering.\n",
    "        end (str or datetime): The end timestamp for filtering.\n",
    "        variable_names (dict): A dictionary where keys are the original column names in df\n",
    "                               and values are the desired new column names.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing the processed data with renamed columns.\n",
    "    \"\"\"\n",
    "    df['valid_dttm'] = pd.to_datetime(df['TIMESTAMP'], utc=True)\n",
    "    df = df[(df['valid_dttm'] >= start) & (df['valid_dttm'] <= end)].copy()\n",
    "    df['valid_dttm'] = df['TIMESTAMP'].view('int64')\n",
    "\n",
    "    # Select and drop rows with NaN values for the specified variables\n",
    "    variables_to_process = list(variable_names.keys())\n",
    "    df = df.dropna(subset=variables_to_process).copy()\n",
    "\n",
    "    df['SID'] = station_info['SID']\n",
    "    df['lat'] = station_info['lat']\n",
    "    df['lon'] = station_info['lon']\n",
    "    df['elev'] = station_info['elev']\n",
    "\n",
    "    # Select the desired columns and rename them\n",
    "    columns_to_select = ['valid_dttm', 'SID', 'lat', 'lon', 'elev'] + variables_to_process\n",
    "    df_processed = df[columns_to_select].rename(columns=variable_names)\n",
    "\n",
    "    return df_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799101ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46edda42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded metadata for station: Majadas_south\n",
      "SID        4300000005\n",
      "lat         39.940556\n",
      "lon         -5.774722\n",
      "elev              258\n",
      "name    Majadas_south\n",
      "Name: 4, dtype: object\n",
      "Fetched data from ICOS.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GPP_DT_VUT_REF</th>\n",
       "      <th>GPP_NT_VUT_REF</th>\n",
       "      <th>H_F_MDS</th>\n",
       "      <th>H_F_MDS_QC</th>\n",
       "      <th>LE_F_MDS</th>\n",
       "      <th>LE_F_MDS_QC</th>\n",
       "      <th>LW_IN_F</th>\n",
       "      <th>LW_IN_F_QC</th>\n",
       "      <th>NEE_VUT_REF</th>\n",
       "      <th>NEE_VUT_REF_QC</th>\n",
       "      <th>...</th>\n",
       "      <th>SW_IN_F</th>\n",
       "      <th>SW_IN_F_QC</th>\n",
       "      <th>TA_F</th>\n",
       "      <th>TA_F_QC</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th>TIMESTAMP_END</th>\n",
       "      <th>VPD_F</th>\n",
       "      <th>VPD_F_QC</th>\n",
       "      <th>WS_F</th>\n",
       "      <th>WS_F_QC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2013-12-31 23:30:00</td>\n",
       "      <td>2014-01-01 00:30:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2014-01-01 00:00:00</td>\n",
       "      <td>2014-01-01 01:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2014-01-01 00:30:00</td>\n",
       "      <td>2014-01-01 01:30:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2014-01-01 01:00:00</td>\n",
       "      <td>2014-01-01 02:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2014-01-01 01:30:00</td>\n",
       "      <td>2014-01-01 02:30:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   GPP_DT_VUT_REF  GPP_NT_VUT_REF  H_F_MDS H_F_MDS_QC  LE_F_MDS LE_F_MDS_QC  \\\n",
       "0             NaN             NaN      NaN          3       NaN           3   \n",
       "1             NaN             NaN      NaN          3       NaN           3   \n",
       "2             NaN             NaN      NaN          3       NaN           3   \n",
       "3             NaN             NaN      NaN          3       NaN           3   \n",
       "4             NaN             NaN      NaN          3       NaN           3   \n",
       "\n",
       "   LW_IN_F LW_IN_F_QC  NEE_VUT_REF NEE_VUT_REF_QC  ...  SW_IN_F SW_IN_F_QC  \\\n",
       "0      NaN          2          NaN              3  ...      NaN          2   \n",
       "1      NaN          2          NaN              3  ...      NaN          2   \n",
       "2      NaN          2          NaN              3  ...      NaN          2   \n",
       "3      NaN          2          NaN              3  ...      NaN          2   \n",
       "4      NaN          2          NaN              3  ...      NaN          2   \n",
       "\n",
       "   TA_F TA_F_QC           TIMESTAMP       TIMESTAMP_END  VPD_F VPD_F_QC  WS_F  \\\n",
       "0   NaN       2 2013-12-31 23:30:00 2014-01-01 00:30:00    NaN        2   NaN   \n",
       "1   NaN       2 2014-01-01 00:00:00 2014-01-01 01:00:00    NaN        2   NaN   \n",
       "2   NaN       2 2014-01-01 00:30:00 2014-01-01 01:30:00    NaN        2   NaN   \n",
       "3   NaN       2 2014-01-01 01:00:00 2014-01-01 02:00:00    NaN        2   NaN   \n",
       "4   NaN       2 2014-01-01 01:30:00 2014-01-01 02:30:00    NaN        2   NaN   \n",
       "\n",
       "  WS_F_QC  \n",
       "0       2  \n",
       "1       2  \n",
       "2       2  \n",
       "3       2  \n",
       "4       2  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 4: Load metadata and fetch data\n",
    "station_metadata = load_station_metadata(station_list_path)\n",
    "station_info = get_station_info(station_name, station_metadata)\n",
    "print(f\"Loaded metadata for station: {station_name}\")\n",
    "print(station_info)\n",
    "df_raw = fetch_flux_data(dataset_doi)\n",
    "#df_raw = fetch_flux_data(dataset_doi, cookie_file_path)\n",
    "print(\"Fetched data from ICOS.\")\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e588a36e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16334/1733085736.py:57: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  df['valid_dttm'] = df['TIMESTAMP'].view('int64')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>valid_dttm</th>\n",
       "      <th>SID</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>elev</th>\n",
       "      <th>H</th>\n",
       "      <th>LE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42337</th>\n",
       "      <td>1464739200000</td>\n",
       "      <td>4300000005</td>\n",
       "      <td>39.940556</td>\n",
       "      <td>-5.774722</td>\n",
       "      <td>258</td>\n",
       "      <td>-7.900000</td>\n",
       "      <td>4.22300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42338</th>\n",
       "      <td>1464741000000</td>\n",
       "      <td>4300000005</td>\n",
       "      <td>39.940556</td>\n",
       "      <td>-5.774722</td>\n",
       "      <td>258</td>\n",
       "      <td>-16.196301</td>\n",
       "      <td>-1.55100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42339</th>\n",
       "      <td>1464742800000</td>\n",
       "      <td>4300000005</td>\n",
       "      <td>39.940556</td>\n",
       "      <td>-5.774722</td>\n",
       "      <td>258</td>\n",
       "      <td>-7.753000</td>\n",
       "      <td>2.78588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42340</th>\n",
       "      <td>1464744600000</td>\n",
       "      <td>4300000005</td>\n",
       "      <td>39.940556</td>\n",
       "      <td>-5.774722</td>\n",
       "      <td>258</td>\n",
       "      <td>-11.108000</td>\n",
       "      <td>2.74053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42341</th>\n",
       "      <td>1464746400000</td>\n",
       "      <td>4300000005</td>\n",
       "      <td>39.940556</td>\n",
       "      <td>-5.774722</td>\n",
       "      <td>258</td>\n",
       "      <td>-13.969000</td>\n",
       "      <td>4.66500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          valid_dttm         SID        lat       lon  elev          H  \\\n",
       "42337  1464739200000  4300000005  39.940556 -5.774722   258  -7.900000   \n",
       "42338  1464741000000  4300000005  39.940556 -5.774722   258 -16.196301   \n",
       "42339  1464742800000  4300000005  39.940556 -5.774722   258  -7.753000   \n",
       "42340  1464744600000  4300000005  39.940556 -5.774722   258 -11.108000   \n",
       "42341  1464746400000  4300000005  39.940556 -5.774722   258 -13.969000   \n",
       "\n",
       "            LE  \n",
       "42337  4.22300  \n",
       "42338 -1.55100  \n",
       "42339  2.78588  \n",
       "42340  2.74053  \n",
       "42341  4.66500  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 5: Process and preview final data\n",
    "df_processed = process_data(df_raw, station_info, start_date, end_date, variables)\n",
    "df_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2fede7e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data written to /home/pn56/OSVASgh/observations/Majadas_south/OBSTABLE_2016.sqlite\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Write to SQLite\n",
    "year = pd.to_datetime(start_date).year\n",
    "output_dir = os.path.join(OSVAS,\"SYNOP\",station_name)\n",
    "os.makedirs(output_dir, exist_ok=True) # Create directory if it doesn't exist\n",
    "output_file = os.path.join(output_dir, f\"OBSTABLE_{year}.sqlite\")\n",
    "\n",
    "\n",
    "with sqlite3.connect(output_file) as conn:\n",
    "    df_processed.to_sql(\"SYNOP\", conn, if_exists=\"replace\", index=False)\n",
    "\n",
    "    conn.execute(\"DROP TABLE IF EXISTS tmp\")\n",
    "    conn.execute(\"\"\"\n",
    "        CREATE TABLE tmp (\n",
    "            valid_dttm REAL,\n",
    "            SID REAL,\n",
    "            lat REAL,\n",
    "            lon REAL,\n",
    "            elev REAL,\n",
    "            H REAL,\n",
    "            LE REAL\n",
    "        )\n",
    "    \"\"\")\n",
    "    conn.execute(\"INSERT INTO tmp SELECT * FROM observations\")\n",
    "    conn.execute(\"DROP TABLE observations\")\n",
    "    conn.execute(\"ALTER TABLE tmp RENAME TO observations\")\n",
    "\n",
    "print(f\"Data written to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b23cfed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
